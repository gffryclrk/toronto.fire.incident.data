---
title: "CMTH642 Capstone"
author: "Geoffrey Clark"
date: "May 28, 2018"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Fire Incident Data Overview

```{r}
## Incidents
# Load & Combine Dataset from Yearwise .csv

I <- read.csv("../csv/2011_i.csv", header=T, stringsAsFactors = F, na.strings=c("","NA"))
# importSchema = c("character", "factor", "POSIXct", "POSIXct", "factor", "factor", "factor", "factor", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "factor", "factor", "character", "character", "character", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "character", "factor", "factor", "character", "character", "character", "character", "character", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "character", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "character", "factor", "factor", "factor", "factor", "factor")


metadata <- data.frame('year'=c(2011), 'nrow'=nrow(I))

for(yr in (2012:2016)){
  i_file <- paste("../csv/",yr, "_i.csv", sep="")
  
  # I <- rbind(I, read.csv(i_file, header=T))
  i_df <- read.csv(i_file, header=T, stringsAsFactors = F)
  metadata <- rbind(metadata, c(yr, nrow(i_df)))
  I <- rbind(I, i_df)
  i_df <- NULL # keeps the environment tidy
}


# I$ARRIVE_DATE <- as.POSIXct(I$ARRIVE_DATE)
# str(I)

# sapply(I, summary)

```

```{r}
## Responding Units
# Load & Combine Dataset from Yearwise .csv

RU <- read.csv("../csv/2011_ru.csv", header=T, stringsAsFactors = F, na.strings=c("","NA"))

ru_metadata <- data.frame('year'=c(2011), 'nrow'=nrow(RU))

for(yr in (2012:2016)){
  r_file <- paste("../csv/",yr, "_ru.csv", sep="")
  
  r_df <- read.csv(r_file, header=T, stringsAsFactors = F)
  ru_metadata <- rbind(ru_metadata, c(yr, nrow(r_df)))
  RU <- rbind(RU, r_df)
  r_df <- NULL # keeps the environment tidy
}


```

```{r}
## Dates
# In this section I work with the three date features: DISPATCH_DATE, ARRIVE_DATE & INCIDENT_DATE
# In fact, DISPATCH_DATE & ARRIVE_DATE are identical so I drop one (arbitrary choice: ARRIVE_DATE)

# This is some of the initial exploring of the dates I did before noticing that DISPATCH & ARRIVE dates were identical.
# I've left the code here for observation. It's commented out to save computation time & resources

# nrow(I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),]) #16802
# nrow(I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$ARRIVE_DATE),]) #16802
# nrow(I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$ARRIVE_DATE) & !grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),])

# Originally I was reading characters in from the .csv as factors. I changed this to reduce overhead. 
# I$DISPATCH_DATE <- as.character(I$DISPATCH_DATE)
# I$ARRIVE_DATE <- as.character(I$ARRIVE_DATE)
# I$INCINCIDENT_DATE <- as.character(I$INCIDENT_DATE) 

# I[,c('DISPATCH_DATE','ARRIVE_DATE')] <- as.character(I[,c('DISPATCH_DATE','ARRIVE_DATE')]) # Slow

# I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$ARRIVE_DATE) & !grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),'DISPATCH_DATE'] <- NA
# I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$ARRIVE_DATE) & !grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),'ARRIVE_DATE'] <- NA
# I[!grepl("\\d{2}/\\d{2}/\\d{4}", I$INCIDENT_DATE),'INCIDENT_DATE'] <- NA # Everyone obs. has a value

# nrow(I[!grepl("\\d{2}/\\d{2}/\\d{4}", I$INCIDENT_DATE),]) # 0


if(identical(I$DISPATCH_DATE, I$ARRIVE_DATE)){ I$ARRIVE_DATE <- NULL }

I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),'DISPATCH_DATE'] <- NA
# Cannot set to date type because of 16,802 Missing Values
I$DISPATCH_DATE <- as.POSIXct(I$DISPATCH_DATE)
# I$ARRIVE_DATE <- as.POSIXct(I$ARRIVE_DATE) # I set I$ARRIVE_DATE to null, above
I$INCIDENT_DATE <- as.POSIXct(I$INCIDENT_DATE, format="%d/%m/%Y")
# td <- as.Date(I$INCIDENT_DATE, format="%d/%m/%Y")

sapply(I[,c('DISPATCH_DATE','INCIDENT_DATE')], function(x) sum(is.na(x)))
# sapply(I, function(x) sum(is.na(x))/nrow(I))
```
## Factors

```{r}
# This was a tricky part of the data prep to handle. This is a relatively sparse dataset (see below for NA quantities!)
# but also has a lot of factors. I decided to keep the NAs as a level in the factors to illustrate restrictions
# in the analysis introduced by such sparse data. 
factorSchema <- c("EVENT_TYPE","EVENT_TYPE_CD","MAIN_STREET","CROSS_STREET","FSA","ALARM_TO_FD","RESPONSE_TYPE","STATUS_ON_ARRIVAL","WATER","FIRE_CONTROL","PROPERTY","AREA_OF_ORIGIN","IGNITION_SOURCE","FUEL_OF_IGNITION_SOURCE","OBJECT_OR_MATERIAL_FIRST_IGNITED","POSSIBLE_CAUSE","VEH_PURPOSE","VEH_FUEL","INSURANCE_ESTIMATE","EST_VALUE_AT_RISK","PHYSICAL_CONDITION_1","PHYSICAL_CONDITION_2","PHYSICAL_CONDITION_3","CIV_FIRE_CONTROL","CIV_EVACUATION","CIV_EVACUATION_REASON_1","CIV_EVACUATION_REASON_2","OPP","MOE","TSSA","ESA","MOL","EMS","CANUTEC","GAS","HYDRO","MUNICIPAL_BUILDING_OFFICE","MUNICIPAL_HEALTH_OFFICE","MUNICIPAL_POLICE","OTHER","INITIAL_DETECTION","EXTENT_FIRE","EXTENT_SMOKE","POSSIBLE_BUSINESS_IMPACT","OCC_STATUS","OCC_TYPE","BLD_STATUS","BLD_HEIGHT","LEVEL_OF_ORIGIN","AGE_OF_STRUCTURE","SMOKE_ALARM_PRESENCE_AND_OPERATION_MAIN_FLOOR","SMOKE_ALARM_FAILURE_TO_OPERATE","SMOKE_ALARM_TYPE","SMOKE_ALARM_OTHER_FLOOR_PRESENCE","SMOKE_ALARM_ON_ALL_FLOORS","SMOKE_ALARM_IMPACT_ON_EVAC","FIRE_ALARM_SYSTEM_PRESENCE","FIRE_ALARM_SYSTEM_OPERATION","FIRE_ALARM_SYSTEM_IMPACT","SPRINKLER_SYSTEM_PRESENCE","SPRINKLER_SYSTEM_ACTIVATION")

for(ft in factorSchema){
  # cat(ft, "\n")
  I[,ft] <- addNA(I[,ft]) # creates factors with NA level
}
```

```{r}
# This sapply returns column NAs as percentage of total
# but doesn't format the output as nicely as the below function which I kept. 
# 
# sapply(I, function(x){
#   per <- sum(is.na(x))/nrow(I)
#   if(per * 100 > 0.001) return(per*100)
#   return(0)
# })


# outputs number of NAs per column as a percent
# format & round because big floats being returned & hard to read.
sapply(I, function(x){
  
  p <- sum(is.na(x))/nrow(I)
  format(round(p*100, 2), nsmall=2)
})

sapply(I, function(x) sum(is.na(x)))
# apply(I, 2, function(x) sum(is.na(x))/nrow(I))
# apply(I, 1, function(x) sum(is.na(x))/ncol(I))

I$ROW_NAS <- apply(I, 1, function(x) sum(is.na(x)))

summary(I$ROW_NAS)
```


```{r}
# https://www.stat.berkeley.edu/~s133/dates.html
# Some cool temporal breakdowns
table(format(I$INCIDENT_DATE, '%Y')) 
table(format(I$INCIDENT_DATE, '%A'))
table(format(I$INCIDENT_DATE, '%B'))
table(format(I$DISPATCH_DATE, '%H'))
table(I$PROPERTY)
# INCIDENT_NUMBER & FD_STATION have a lot of similarities...
sum(I$INCIDENT_NUMBER == substr(I$FD_STATION,0,9), na.rm=T) #375456
length(unique(I$FD_STATION)) #375478
```

```{r}
# https://www.quora.com/How-do-I-get-a-frequency-count-based-on-two-columns-variables-in-an-R-dataframe?share=1

# I'm trying to build a cross-table

I$PROPERTY_GROUP <- vector(mode='character', length=nrow(I))
# I[I$PROPERTY]
PROPERTY_GROUP <- list()
PROPERTY_GROUP$A <- (101:199)
PROPERTY_GROUP$B <- (201:299)
PROPERTY_GROUP$C <- (301:399)
PROPERTY_GROUP$D <- (401:499)
PROPERTY_GROUP$E <- (501:599)
PROPERTY_GROUP$F <- (601:799)
PROPERTY_GROUP$O <- (801:999)

for(g in c(LETTERS[(1:6)],'O')){
  I$PROPERTY_GROUP[I$PROPERTY %in% PROPERTY_GROUP[[g]]] <- g
}

table(format(I$INCIDENT_DATE, '%A'), I$PROPERTY_GROUP) # This is Day of week vs Property Group
```

```{r}
MEDICAL <- I[I$EVENT_TYPE %in% 'Medical',]
table(format(MEDICAL$INCIDENT_DATE, '%A'), MEDICAL$PROPERTY_GROUP)

tta <- function(x){
 # print(x);
  # print(x$INITIAL_CALL_HOUR)
  if(!is.na(I$INITIAL_CALL_HOUR) & !is.na(I$ONSCENE_HOUR) & I$ONSCENE_HOUR < I$INITIAL_CALL_HOUR){
    
  }else if(){
    
  }else{
    
  }
}
# I[!is.na(I$INITIAL_CALL_HOUR) & !is.na(I$ONSCENE_HOUR) & I$ONSCENE_HOUR < I$INITIAL_CALL_HOUR,] #Rollover dispatch
```

