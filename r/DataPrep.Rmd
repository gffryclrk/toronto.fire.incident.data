---
title: "CMTH642 Capstone"
author: "Geoffrey Clark"
date: "May 28, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Fire Incident Data Overview
### Input Data: Incidents
```{r}
## Incidents
# Load & Combine Dataset from Yearwise .csv

I <- read.csv("../csv/2011_i.csv", header=T, stringsAsFactors = F, na.strings=c("","NA", " "))
# importSchema = c("character", "factor", "POSIXct", "POSIXct", "factor", "factor", "factor", "factor", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "character", "factor", "factor", "character", "character", "character", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "character", "factor", "factor", "character", "character", "character", "character", "character", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "character", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "factor", "character", "factor", "factor", "factor", "factor", "factor")


# metadata <- data.frame('year'=c(2011), 'nrow'=nrow(I))

for(yr in (2012:2016)){
  i_file <- paste("../csv/",yr, "_i.csv", sep="")
  
  # I <- rbind(I, read.csv(i_file, header=T))
  i_df <- read.csv(i_file, header=T, stringsAsFactors = F)
  # metadata <- rbind(metadata, c(yr, nrow(i_df)))
  I <- rbind(I, i_df)
  i_df <- NULL # keeps the environment tidy
}


# I$ARRIVE_DATE <- as.POSIXct(I$ARRIVE_DATE)
# str(I)

# sapply(I, summary)

```


### Input Data: Responding Units
```{r}
## Responding Units
# Load & Combine Dataset from Yearwise .csv

RU <- read.csv("../csv/2011_ru.csv", header=T, stringsAsFactors = F, na.strings=c("","NA"))


for(yr in (2012:2016)){
  r_file <- paste("../csv/",yr, "_ru.csv", sep="")
  
  r_df <- read.csv(r_file, header=T, stringsAsFactors = F)
  RU <- rbind(RU, r_df)
  r_df <- NULL # keeps the environment tidy
}


```

## Working with R Data Types
### Dates

```{r}
## Dates
# In this section I work with the three date features: DISPATCH_DATE, ARRIVE_DATE & INCIDENT_DATE
# In fact, DISPATCH_DATE & ARRIVE_DATE are identical so I drop one (arbitrary choice: ARRIVE_DATE)

# This is some of the initial exploring of the dates I did before noticing that DISPATCH & ARRIVE dates were identical.
# I've left the code here for observation. It's commented out to save computation time & resources

# nrow(I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),]) #16802
# nrow(I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$ARRIVE_DATE),]) #16802
# nrow(I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$ARRIVE_DATE) & !grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),])

# Originally I was reading characters in from the .csv as factors. I changed this to reduce overhead. 
# I$DISPATCH_DATE <- as.character(I$DISPATCH_DATE)
# I$ARRIVE_DATE <- as.character(I$ARRIVE_DATE)
# I$INCINCIDENT_DATE <- as.character(I$INCIDENT_DATE) 

# I[,c('DISPATCH_DATE','ARRIVE_DATE')] <- as.character(I[,c('DISPATCH_DATE','ARRIVE_DATE')]) # Slow

# I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$ARRIVE_DATE) & !grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),'DISPATCH_DATE'] <- NA
# I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$ARRIVE_DATE) & !grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),'ARRIVE_DATE'] <- NA
# I[!grepl("\\d{2}/\\d{2}/\\d{4}", I$INCIDENT_DATE),'INCIDENT_DATE'] <- NA # Everyone obs. has a value

# nrow(I[!grepl("\\d{2}/\\d{2}/\\d{4}", I$INCIDENT_DATE),]) # 0


if(identical(I$DISPATCH_DATE, I$ARRIVE_DATE)){ I$ARRIVE_DATE <- NULL }

I[!grepl("\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}", I$DISPATCH_DATE),'DISPATCH_DATE'] <- NA
# Cannot set to date type because of 16,802 Missing Values
I$DISPATCH_DATE <- as.POSIXct(I$DISPATCH_DATE)
# I$ARRIVE_DATE <- as.POSIXct(I$ARRIVE_DATE) # I set I$ARRIVE_DATE to null, above
I$INCIDENT_DATE <- as.POSIXct(I$INCIDENT_DATE, format="%d/%m/%Y")
# td <- as.Date(I$INCIDENT_DATE, format="%d/%m/%Y")

sapply(I[,c('DISPATCH_DATE','INCIDENT_DATE')], function(x) sum(is.na(x)))
# sapply(I, function(x) sum(is.na(x))/nrow(I))
```
### Factors
There are many categorical features in this dataset. I decided to encode them as factors. Empty & blank values are treated as NA. 

```{r}
# This was a tricky part of the data prep to handle. This is a relatively sparse dataset (see below for NA quantities!)
# but also has a lot of factors. I decided to keep the NAs as a level in the factors to illustrate restrictions
# in the analysis introduced by such sparse data. 
factorSchema <- c("EVENT_TYPE","EVENT_TYPE_CD","MAIN_STREET","CROSS_STREET","FSA","ALARM_TO_FD","RESPONSE_TYPE","STATUS_ON_ARRIVAL","WATER","FIRE_CONTROL","PROPERTY","AREA_OF_ORIGIN","IGNITION_SOURCE","FUEL_OF_IGNITION_SOURCE","OBJECT_OR_MATERIAL_FIRST_IGNITED","POSSIBLE_CAUSE","VEH_PURPOSE","VEH_FUEL","INSURANCE_ESTIMATE","EST_VALUE_AT_RISK","PHYSICAL_CONDITION_1","PHYSICAL_CONDITION_2","PHYSICAL_CONDITION_3","CIV_FIRE_CONTROL","CIV_EVACUATION","CIV_EVACUATION_REASON_1","CIV_EVACUATION_REASON_2","OPP","MOE","TSSA","ESA","MOL","EMS","CANUTEC","GAS","HYDRO","MUNICIPAL_BUILDING_OFFICE","MUNICIPAL_HEALTH_OFFICE","MUNICIPAL_POLICE","OTHER","INITIAL_DETECTION","EXTENT_FIRE","EXTENT_SMOKE","POSSIBLE_BUSINESS_IMPACT","OCC_STATUS","OCC_TYPE","BLD_STATUS","BLD_HEIGHT","LEVEL_OF_ORIGIN","AGE_OF_STRUCTURE","SMOKE_ALARM_PRESENCE_AND_OPERATION_MAIN_FLOOR","SMOKE_ALARM_FAILURE_TO_OPERATE","SMOKE_ALARM_TYPE","SMOKE_ALARM_OTHER_FLOOR_PRESENCE","SMOKE_ALARM_ON_ALL_FLOORS","SMOKE_ALARM_IMPACT_ON_EVAC","FIRE_ALARM_SYSTEM_PRESENCE","FIRE_ALARM_SYSTEM_OPERATION","FIRE_ALARM_SYSTEM_IMPACT","SPRINKLER_SYSTEM_PRESENCE","SPRINKLER_SYSTEM_ACTIVATION")

# grepl(".*\\S.*", "   ") # True if there's anything besides whitespace. 

for(ft in factorSchema){
  I[!grepl(".*\\S.*", I[,ft]),ft] <- NA
  I[,ft] <- addNA(I[,ft]) # creates factors with NA level
}
```

### Counting NAs
```{r}
# This sapply returns column NAs as percentage of total
# but doesn't format the output as nicely as the below function which I kept. 
# 
# sapply(I, function(x){
#   per <- sum(is.na(x))/nrow(I)
#   if(per * 100 > 0.001) return(per*100)
#   return(0)
# })


# outputs number of NAs per column as a percent
# format & round because big floats being returned & hard to read.
sapply(I, function(x){
  
  p <- sum(is.na(x))/nrow(I)
  format(round(p*100, 2), nsmall=2)
})

# sapply(I, function(x) sum(is.na(x)))
# apply(I, 2, function(x) sum(is.na(x))/nrow(I))
# apply(I, 1, function(x) sum(is.na(x))/ncol(I))

I$ROW_NAS <- apply(I, 1, function(x) sum(is.na(x)))

summary(I$ROW_NAS)
summary(I)
# I[!grepl(".*\\S.*", I[,ft]),ft] <- NA
# sum(!grepl(".*\\S.*", I$FD_STATION))
```
### More work on NAs
One thing I have noticed is that quite a few columns have exactly the same number of NAs.
What types of incidents are these?

After an initial glance these incidents seem to be mostly fires. 

```{r}
NA_cols <- c('COMPLEX','OCC_STATUS','OCC_type','BLD_STATUS','BLD_HEIGHT','LEVEL_OF_ORIGIN','AGE_OF_STRUCTURE','SMOKE_ALARM_PRESENCE_AND_OPERATION_MAIN_FLOOR','SMOKE_ALARM_FAILURE_TO_OPERATE','SMOKE_ALARM_TYPE','SMOKE_ALARM_OTHER_FLOOR_PRESENCE','SMOKE_ALARM_ON_ALL_FLOORS','SMOKE_ALARM_IMPACT_ON_EVAC','FIRE_ALARM_SYSTEM_PRESENCE','FIRE_ALARM_SYSTEM_OPERATION','FIRE_ALARM_SYSTEM_IMPACT','SPRINKLER_SYSTEM_PRESENCE','SPRINKLER_SYSTEM_ACTIVATION')

FIRES <- I[
  !is.na(I$COMPLEX) &
  !is.na(I$OCC_STATUS) &
  !is.na(I$OCC_TYPE) &
  !is.na(I$BLD_STATUS) &
  !is.na(I$BLD_HEIGHT) & 
  !is.na(I$LEVEL_OF_ORIGIN) &
  !is.na(I$AGE_OF_STRUCTURE) &
  !is.na(I$SMOKE_ALARM_PRESENCE_AND_OPERATION_MAIN_FLOOR) &
  !is.na(I$SMOKE_ALARM_FAILURE_TO_OPERATE) &
  !is.na(I$SMOKE_ALARM_TYPE) &
  !is.na(I$SMOKE_ALARM_ON_ALL_FLOORS) &
  !is.na(I$SMOKE_ALARM_IMPACT_ON_EVAC) &
  !is.na(I$FIRE_ALARM_SYSTEM_PRESENCE) &
  !is.na(I$FIRE_ALARM_SYSTEM_IMPACT) &
  !is.na(I$SPRINKLER_SYSTEM_PRESENCE) &
  !is.na(I$SPRINKLER_SYSTEM_ACTIVATION)
,]

table(FIRES$PROPERTY_GROUP)/length(FIRES$PROPERTY_GROUP)
table(I$PROPERTY_GROUP)/length(I$PROPERTY_GROUP)


```

## Feature Selection
### INCIDENT_NUMBER & FD_STATION
As I continue my exploratory data analysis I keep finding features that appear, at first glance, to be completely redundant. A prime example of such a feature is FD_STATION: The below call to pbapply returns 720340. Only 30 entries don't correspond to this pattern! Of that 30, 6 are NA and the other 24 are simply blank strings in the INCIDENT_NUMBER field.


```{r}
sum(substring(I$FD_STATION, 0, nchar(I$INCIDENT_NUMBER)) == I$INCIDENT_NUMBER | I$FD_STATION == '0', na.rm=T) #720364

# sum(as.numeric(gsub(I$INCIDENT_NUMBER, "", I$FD_STATION)) == 0, na.rm=T)
sum(pbapply(I[,c('INCIDENT_NUMBER','FD_STATION')],1, function(x){
  as.numeric(gsub(x['INCIDENT_NUMBER'],'',x['FD_STATION'])) == 0
}), na.rm=T) #returns 720340

in_eq_fdstn <- pbapply(I[,c('INCIDENT_NUMBER','FD_STATION')],1, function(x){
  as.numeric(gsub(x['INCIDENT_NUMBER'],'',x['FD_STATION'])) == 0
})

```


### Some preliminary cross-tables

```{r}
# https://www.stat.berkeley.edu/~s133/dates.html
# Some cool temporal breakdowns
table(format(I$INCIDENT_DATE, '%Y')) 
table(format(I$INCIDENT_DATE, '%A'))
table(format(I$INCIDENT_DATE, '%B'))
table(format(I$DISPATCH_DATE, '%H'))
table(I$PROPERTY)
# INCIDENT_NUMBER & FD_STATION have a lot of similarities...
sum(I$INCIDENT_NUMBER == substr(I$FD_STATION,0,9), na.rm=T) #375456
length(unique(I$FD_STATION)) #375478
```

### Grouping Property Type by Category

```{r}
# https://www.quora.com/How-do-I-get-a-frequency-count-based-on-two-columns-variables-in-an-R-dataframe?share=1

# I'm trying to build a cross-table

I$PROPERTY_GROUP <- vector(mode='character', length=nrow(I))
# I[I$PROPERTY]
PROPERTY_GROUP <- list()
PROPERTY_GROUP$A <- (101:199)
PROPERTY_GROUP$B <- (201:299)
PROPERTY_GROUP$C <- (301:399)
PROPERTY_GROUP$D <- (401:499)
PROPERTY_GROUP$E <- (501:599)
PROPERTY_GROUP$F <- (601:799)
PROPERTY_GROUP$O <- (801:999)

for(g in c(LETTERS[(1:6)],'O')){
  I$PROPERTY_GROUP[I$PROPERTY %in% PROPERTY_GROUP[[g]]] <- g
}

I[I$PROPERTY_GROUP == "", 'PROPERTY_GROUP'] <- NA
table(format(I$INCIDENT_DATE, '%A'), I$PROPERTY_GROUP) # This is Day of week vs Property Group
```

### Response Time (Time-to-arrival)

For this 'new' feature I subtracted response time, or Time-to-arrival, by subtracting the ONSCENE_TIME from the INITIAL_CALL_TIME, both of which were fairly complete in the dataset. I found that the dataset was encoded such that INCIDENT_DATE was always the date of the initial call. For cases where the call was received late at night, say 11:59pm, and the Responding Units didn't arrive until the next day I added one day (24 * 60 * 60 seconds) to the INCIDENT_DATE used for ONSCENE TIME.

I wrote a function to make this calculation, below, and passed it the rows of the dataset, one at a time, using apply. This process took some time to compute on my mid 2009 MacBook. Originally approximately 25 minutes, I was able to reduce it to 15 minutes by simplifying the function a bit and also only passing the relevant columns to apply.

```{r}
MEDICAL <- I[I$EVENT_TYPE %in% 'Medical',]
table(format(MEDICAL$INCIDENT_DATE, '%A'), MEDICAL$PROPERTY_GROUP)

# This below function calculates time difference between time call was received
# and recorded onscene time. I accounted for cases where the date would roll over between call & arrival.
# However, I later realized that the data itself is encoded to account for this: 
# DISPATCH_DATE includes the date & time of ONSCENE whereas INCIDENT_DATE is the date of call. 


tta <- function(x){
  if(sum(is.na(c(x["INCIDENT_DATE"], x["INITIAL_CALL_HOUR"], x["INITIAL_CALL_MIN"], x["INITIAL_CALL_SEC"], x["ONSCENE_HOUR"],x["ONSCENE_MIN"],x["ONSCENE_SEC"]))) > 0) return(NA)
  # onscene_date <- x["INCIDENT_DATE"]
  ic <- as.POSIXct(paste0(
    x["INCIDENT_DATE"], " ", x["INITIAL_CALL_HOUR"], ":", x["INITIAL_CALL_MIN"], ":", x["INITIAL_CALL_SEC"] 
  ), format="%Y-%m-%d %H:%M:%S", tz="EST")
  os <- as.POSIXct(paste0(
    x["INCIDENT_DATE"], " ", x["ONSCENE_HOUR"], ":", x["ONSCENE_MIN"], ":", x["ONSCENE_SEC"]
  ), format="%Y-%m-%d %H:%M:%S", tz="EST")
  if(x["ONSCENE_HOUR"] < x["INITIAL_CALL_HOUR"]){ os <- os + (24 * 60 * 60) }
  return(as.numeric(os) - as.numeric(ic))
  
}




# I[!is.na(I$INITIAL_CALL_HOUR) & !is.na(I$ONSCENE_HOUR) & I$ONSCENE_HOUR < I$INITIAL_CALL_HOUR,] #Rollover dispatch
# nrow(I[!is.na(I$INITIAL_CALL_HOUR) & !is.na(I$ONSCENE_HOUR) & I$ONSCENE_HOUR < I$INITIAL_CALL_HOUR,]) #2519

# Below is the code to actually create the 'TTA' column: First an empty numeric vector, later populated with the call to apply(). This call took about 15 minutes to run. I used pbapply, from the pabbly package, for the progress bar  (very handy!)
#
# library(pbapply)
# I$TTA <- vector(length=nrow(I), mode="numeric")
# I$TTA <- pbapply(I[,c('INCIDENT_DATE','INITIAL_CALL_HOUR','INITIAL_CALL_MIN','INITIAL_CALL_SEC','ONSCENE_HOUR','ONSCENE_MIN','ONSCENE_SEC')], 1, tta)
# 
# Since I have already calculated the TTA values I save I save time when loading the project by either saving the .RData or writing the columns as a .csv and re-loading the TTA feature back into I. 
# write.csv(x=I[,c('INCIDENT_NUMBER','TTA')], file="TTA.csv")
# TTA <- read.csv(file="../csv/TTA.csv", header = T)
# I <- cbind(I, TTA$TTA)
# names(I)[101] <- "TTA"

# Now that we have TTA we can do some cool cross-tables
tapply(I$TTA, I$PROPERTY_GROUP, mean, na.rm=T)

# Trying to test the above: Boolean "is DISPATCH_DATE" time always ONSCENE time?
sum(format(I$DISPATCH_DATE, format='%Y-%m-%d') == I$INCIDENT_DATE, na.rm=T) # 701044
sum(I$INITIAL_CALL_HOUR > I$ONSCENE_HOUR, na.rm=T) # 2519
nrow(I[!is.na(I$DISPATCH_DATE) & format(I$DISPATCH_DATE, format='%Y-%m-%d') != I$INCIDENT_DATE,]) # 2524

# There seem to be a few observations (17) that don't fit the pattern:
# Incident Date: Date initial call was received
# Dispatch Date: Date & Time first responders arrive on scene
# I'm guessing that these cases are a result of a data input error. After briefly browsing aforementioned 17 records, 
# I noticed some of the fields don't match up: Control date, when inputted, close to incident or dispach date.. Also the times used tend to be all over the place and don't correspond to other columns. 
# I might remove these observations entirely. 

nrow(I[!is.na(I$DISPATCH_DATE) & format(I$DISPATCH_DATE, format='%Y-%m-%d') != I$INCIDENT_DATE & I$INITIAL_CALL_HOUR <= I$ONSCENE_HOUR,]) # 17
# total obs - (# dispatch date = incident date) - (#edge cases) - (Dispatch Date NAs) 
# = 720370 - 701044 - 2519 - 16802  

# The below lines are to calculate edge cases. A Date is said to be "less than" another date if it occurred before the date being compared to. Example: January 1st, 1980 < January 2nd, 1980. This is easier to remember if you think of dates in terms of 'Unix seconds' wheras the integer value equality holds. 
# 
sum(I$DISPATCH_DATE > I$INCIDENT_DATE, na.rm=T) # 703568
sum(is.na(I$DISPATCH_DATE > I$INCIDENT_DATE)) # 16802
sum(I[!is.na(I$DISPATCH_DATE), 'DISPATCH_DATE'] > I[!is.na(I$DISPATCH_DATE), 'INCIDENT_DATE'])
sum(is.na(I$DISPATCH_DATE)) + sum(I[!is.na(I$DISPATCH_DATE), 'DISPATCH_DATE'] > I[!is.na(I$DISPATCH_DATE), 'INCIDENT_DATE']) == nrow(I)

```

```{r}
aggregate(I$TTA, list(I$PROPERTY_GROUP), mean, na.rm=T)
table(I$PROPERTY_GROUP)
summary(I)
sum(I$TTA == 0, na.rm = T)
```
### More Cross Tables

```{r}
et_vs_atofd <- addmargins(table(I$EVENT_TYPE, I$ALARM_TO_FD), 2)

```

